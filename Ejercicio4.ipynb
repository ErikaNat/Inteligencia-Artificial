{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gvjP20uR-utObo-iDf8vyVe9uZvx2k_6",
      "authorship_tag": "ABX9TyNwK4kc+Yz812GsJuOcblvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErikaNat/Inteligencia-Artificial/blob/main/Ejercicio4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwqvLCKsk5HD",
        "outputId": "64542903-39a0-4801-9612-88ea874ed502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6447513812154696\n"
          ]
        }
      ],
      "source": [
        " #Ejercicio 3: Red neuronal en el dataset Iris\n",
        " from sklearn.datasets import load_iris\n",
        " from sklearn.model_selection import train_test_split #Dividir dats en base de entrenamiento y testing\n",
        "\n",
        " #Eb 5\n",
        " from sklearn.neural_network import MLPClassifier\n",
        " from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        " #Cargar dataset Iris\n",
        "dataset = pd.read_csv('/content/anime.csv')\n",
        "\n",
        "# Assuming 'rating' is the target variable and the rest are features\n",
        "# Drop non-numeric columns before training the model\n",
        "x = dataset[['anime_id', 'members']]\n",
        "y = dataset['rating']\n",
        "\n",
        "# Drop rows with NaN in the target variable\n",
        "data = pd.concat([x, y], axis=1).dropna()\n",
        "x = data[['anime_id', 'members']]\n",
        "y = data['rating']\n",
        "\n",
        "# Discretize the 'rating' column into bins for classification\n",
        "# Define the number of bins (e.g., 5 bins)\n",
        "num_bins = 5\n",
        "data['rating_category'] = pd.cut(data['rating'], bins=num_bins, labels=False)\n",
        "y = data['rating_category']\n",
        "\n",
        "\n",
        "#Dividir en entrenamiento y prueba\n",
        "x_train , x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42) #0.3 es para test porcentaje. puede ser 0 o 42 (42 es estandar )\n",
        "\n",
        "#Crear modelp\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(7,13), activation=\"relu\", max_iter=2000) #trabajo dos capas de 10 neuronas cada una\n",
        "\n",
        "#Entrenar el modelo\n",
        "mlp.fit(x_train, y_train)\n",
        "\n",
        "#Evaluar\n",
        "y_pred = mlp.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    }
  ]
}